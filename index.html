---
layout: default
tags: about
---
<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9NY2CVV92L"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9NY2CVV92L');
  </script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script type="text/javascript">
    function readMore() {
        $('#readMore').hide();
        $('#more').show ();
    }

    function readLess() {
        $('#readMore').show();
        $('#more').hide();
    }
</script>

<style>
  p.normal {font-style:normal;}
  p.italic {font-style:italic; color:darkred}
  p.oblique {font-style:oblique;}
</style>

</head>

<body>


<div class="bio" style="text-align:justify">
      <p>
         I am a first-year PhD at Multimedia Lab (MMLab) in the Chinese University of Hong Kong, working with <a href="https://xyue.io/" class="uline">Prof. Xiangyu Yue. Previously, I'm a master student at Beijing Institute of Technology (BIT), advised by <a href="https://cs.bit.edu.cn/szdw/jsml/gjjgccrc/lcs_e253eb02bdf246c4a88e1d2499212546/index.htm" class="uline">Prof. Changsheng Li</a>. I received my Bachelor's degree in Computer Science from <a href="https://www.bit.edu.cn" class="uline">BIT</a> (2018 - 2022).   
      </p>

      <p>
        My research interests include MLLMs and AIGC. 
      </p>
        <p>
          Email: kaituofeng[at]gmail[dot]com
        </p>
        <p>
          [<a href="https://scholar.google.com/citations?user=m1iCh00AAAAJ&hl=en" class="uline">Google Scholar</a>]  [<a href="https://github.com/tulerfeng" class="uline">Github</a>] 
      </p>
        <br/>
</div> 

<!-- <hr />
<div class="news">
    <h2>News</h2>
    <br />
    <ul>
      <li>
        <p>[July 2022] One paper was accepted by ACM Multimedia (ACM MM) 2022!</p>
      </li>
        <li>
          <p>[Apr 2022] <a href='https://ieeexplore.ieee.org/document/9756672' class='uline'>Critical Classes and Samples Discovering for Partial Domain Adaptation</a> was accepted to IEEE Transaction on Cybernetics (IF: 11.44)!</p>
        </li>
        <li>
            <p>[July 2021] <a href='https://proceedings.neurips.cc/paper/2021/file/6ba3af5d7b2790e73f0de32e5c8c1798-Paper.pdf' class='uline'>Pareto Domain Adaptation </a> was accepted to NeurIPS 2021! </p>
          </li>
          <li>
              <p>[Apr 2021] Two papers (One <font color="red">Oral</font>) were accepted to CVPR 2021!</p>
          </li>
          
    </ul>
</div>

<hr /> -->

<div id="research">
    <h2><a name="research">Selected Publications</a></h2>
    <br />
    <table width="100%" align="center" cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
        <tbody>
          


          <!-- CVPR PlanKD -->
          <tr>
              <td valign="middle" width="35%">
                  <div class="one" style="text-align:center;">
                      <img src="images/plankd.png" style="max-height: 300px;">
                  </div>
              </td>
              <td valign="middle" width="65%">
                  <h5>
                    On the Road to Portability: Compressing End-to-End Motion Planner for Autonomous Driving
                  </h5>
                  <p>
                      <a href="https://cvpr.thecvf.com/Conferences/2024" class="uline-special"><span style="color:red">CVPR 2024</span></a>
                  </p>
                  <p>
                      <b>Kaituo Feng</b>, Changsheng Li, Dongchun Ren, Ye Yuan, Guoren Wang
                  </p>
                  <p>
                    We constitute the first attempt to explore a knowledge distillation method to compress end-to-end autonomous driving planners.
                  </p>
                  <a href="https://arxiv.org/abs/2403.01238" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Paper</a>
                  <a href="https://github.com/tulerfeng/PlanKD" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Code</a>
              </td>
          </tr>


          <!-- ICML KPOD -->
          <tr>
            <td valign="middle" width="35%">
                <div class="one" style="text-align:center;">
                    <img src="images/kpod.png" style="max-height: 300px;">
                </div>
            </td>
            <td valign="middle" width="65%">
                <h5>
                  Keypoint-based Progressive Chain-of-Thought Distillation for LLMs
                </h5>
                <p>
                    <a href="https://icml.cc/Conferences/2024" class="uline-special"><span style="color:red">ICML 2024</span></a>
                </p>
                <p>
                    <b>Kaituo Feng</b>, Changsheng Li, Xiaolu Zhang, Jun Zhou, Ye Yuan, Guoren Wang
                </p>
                <p>
                  We propose a new compression method to progressively distill the emergent reasoning capabilities of LLMs into smaller models, as well as encouraging the precise mimicry of significant tokens.
                </p>
                <a href="https://arxiv.org/abs/2405.16064" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Paper</a>
            </td>
        </tr>

           
          <!-- ICLR OTGNet -->
          <tr>
            <td valign="middle" width="35%">
                <div class="one" style="text-align:center;">
                    <img src="images/otgnet.png" style="max-height: 300px;">
                </div>
            </td>
            <td valign="middle" width="65%">
                <h5>
                  Towards Open Temporal Graph Neural Networks
                </h5>
                <p>
                    <a href="https://iclr.cc/Conferences/2023" class="uline-special"><span style="color:red">ICLR 2023, Oral, 90/4922</span></a>
                </p>
                <p>
                    <b>Kaituo Feng</b>, Changsheng Li, Xiaolu Zhang, Jun Zhou
                </p>
                <p>
                  We propose the first class-incremental learning for temporal GNNs, allowing temporal graphs to evolve in the real-world scenarios with an open class set
                </p>
                <a href="https://arxiv.org/abs/2303.15015" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Paper</a>
                <a href="https://github.com/tulerfeng/OTGNet" class="btn btn-outline-primary btn-sm" role="button" aria-pressed="true">Code</a>
            </td>
        </tr>



        </tbody>
    </table>
</div>

<hr>




<!-- <div class="news">
  <h2>Academic Service</h2>
  <br />
  <p>
    Serve as a reviewer for IEEE CVPR 2021-2022, AAAI 2021-2022, IEEE ICCV 2021, ECCV 2022 etc.
  </p>
  
</div> -->




<!-- <div class="news">
  <h2>Course</h2>
  <br />
  <p>
    Introduction to Machine Learning, since 2021, Instructor: <a href="https://shuangli.xyz" class="uline">Prof. Li</a> 
  </p>
  
</div> -->


<hr>
<div id="news">
  <h2>Selected Honors and Awards</h2>
  <ul>
    <li>
      <p>
        National Scholarship, Ministry of Education of China (TOP 2%), 2024.
      </p>
    </li>
    <li>
      <p>
        National Scholarship, Ministry of Education of China (TOP 2%), 2023.
      </p>
    </li>
    <li>
      <p>
        Outstanding Undergraduate Student of Beijing Institute of Technology, 2022.
      </p>
    </li>
    <li>
      <p>
        Silver Medal of 45th ACM-ICPC Asia Regional Contest, 2020.
      </p>
    </li>
    <li>
      <p>
        First Prize (top 1%) of China Undergraduate Mathematical Contest in Modeling (CUMCM), 2020.
      </p>
    </li>
    <li>
      <p>
        Gold Medal of Group Programming Ladder Tournament China Finals, 2020.
      </p>
    </li>
  </ul>
</div>

<hr>
<div class="news">
  <h2>Contact</h2>
  <br />
  <ul>
    <li>
        <p>
          Email: kaituofeng@gmail.com
        </p>
    </li>
</ul>

</div>




<!-- <div id="projects">
  <h2>Projects</h2>
  <table width="100%" align="center" cellspacing="0" cellpadding="0" style="border-collapse: collapse;">
    <tbody>
      <tr>
        <td valign="top" width="40%">
          <h5>PyTorch implementation of <a href="https://arxiv.org/" class="uline"> Deep Reinforcement Learning</a></h5>
          <p class="authors">
            <b>Binhui Xie</b>, 
          </p>
          <a href="https://github.com/" class="btn btn-outline-primary btn-sm" role="button"
            aria-pressed="true">Code</a>
        </td>
        <td width="50%">
          <div class="one" style="text-align:center;">
            <div class="two" id="jump_image" style="opacity: 0;"></div>
            <img src="images/drl.jpg" style="margin-top:30px;max-height: 200px;width:100%;">
          </div>
        </td>
      </tr>
    </tbody>
  </table>
</div> -->
        <!-- <hr> -->

</body>
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5n0qvv7rnap&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
</html>
